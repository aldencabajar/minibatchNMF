# beta_nmf_minibatch: NMF with beta-divergence and mini-batch updates

Theano based GPGPU implementation of NMF with beta-diveregence and mini-batch mult^plicative updates.


## Dependencies

bbeta_nmf_minibatch need Python >= 2.7, numpy >= 10.1, Theano >= 0.8, scikit-learn >= 0.17.1, h5py >= 2.5, itertools and more_itertools

## Documentation

Dcoumentation available at http://rserizel.github.io/minibatchNMF/

## Citation

If you are using this source code please consider citing the following paper: 

> R. Serizel, S. Essid, and G. Richard. “Mini-batch stochastic approaches for accelerated multiplicative updates in nonnegative matrix factorisation with beta-divergence”. Accepted for publication In *Proc. of MLSP*, p. 5, 2016.

Bibtex
```
	@inproceedings{serizel2016batch,
  	title={Mini-batch stochastic approaches for accelerated multiplicative updates in nonnegative matrix factorisation with beta-divergence},
  	author={Serizel, Romain and Essid, Slim and Richard, Ga{\"e}l},
  	booktitle={IEEE International Workshop on Machine Learning for Signal Processing (MLSP)},
  	pages={5470--5474},
  	year={2016},
  	organization={IEEE}
	}
```

## Author

Romain Serizel, 2016 -- Present
